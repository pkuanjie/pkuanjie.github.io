<!DOCTYPE HTML>
<html lang="en">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Jie An</title>

    <meta name="author" content="Jie An">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon"
        href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>

    <table
        style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
            <tr style="padding:0px">
                <td style="padding:0px">
                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr style="padding:0px">
                                <td style="padding:2.5%;width:63%;vertical-align:middle">
                                    <p class="name" style="text-align: center;">
                                        Jie An&nbsp <span style="text-align: center; color: #000000; font-size: 24px;">[ÂÆâ&nbspÊç∑]</span>
                                    </p>

                                        <p>Hi! I am an Applied Scientist at Amazon AGI, where I work on image and video generation models as well as omni understanding and generation models. Previously, I was a Research Scientist at Meta Reality Labs, where I worked on 3D generation and world modeling. I received my Ph.D. in Computer Science from <a href="http://www.cs.rochester.edu">University of Rochester</a>, advised by <a href="http://www.cs.rochester.edu/u/jluo/#VISTA">Prof. Jiebo Luo</a>, where I received the <a href="https://www.sigmm.org/Awards/thesisaward">ACM SIGMM Outstanding Ph.D. Thesis Award</a>. Earlier, I earned my bachelor's and master's (with honor) degrees in Applied Mathematics from <a href="https://www.math.pku.edu.cn/puremath_en/">Peking University</a>, advised by <a href="https://www.math.pku.edu.cn/teachers/jwma/homepage/">Prof. Jinwen Ma</a>.</p>

<p>I was a research intern at Apple (Seattle, 2024‚Äì2025), working with Prof. <a href="https://www.alexander-schwing.de/">Alexander Schwing</a>. Before that, I interned at Microsoft Cloud &amp; AI (Redmond, 2023‚Äì2024, now part of Microsoft AI) and Meta FAIR (New York City, 2022), hosted by Dr. <a href="https://zyang-ur.github.io/">Zhengyuan Yang</a> and Prof. <a href="https://scholar.google.com/citations?user=jpIFgToAAAAJ">Harry Yang</a>.</p>

<p>My research primarily focuses on visual content generation. I am particularly interested in foundational generative models, text-to-video generation, physics AI/world modeling, and artistic generation/style transfer. My research is driven by a long-term vision: from developing a fundamental understanding of generative models, to building increasingly capable foundation models, and ultimately advancing toward visual artificial general intelligence (VisualAGI).</p>

                                        <p>Contact: pkuanjie [at] gmail [dot] com</p>


                                    <p style="text-align:center">
                                        <a href="mailto:pkuanjie@gmail.com">Email</a> &nbsp;/&nbsp;
                                        <a href="files/resume.pdf">CV</a> &nbsp;/&nbsp;
                                        <a href="https://scholar.google.com/citations?hl=en&user=pZ-soHUAAAAJ">Google
                                            Scholar</a> &nbsp;/&nbsp;
                                        <a href="https://github.com/pkuanjie">Github</a> &nbsp;/&nbsp;
                                        <a href="https://www.linkedin.com/in/jie-an-477b64202/">LinkedIn</a>
                                        &nbsp;/&nbsp;
                                        <a
                                            href="https://translate.google.com/details?sl=zh-CN&tl=en&text=ÂÆâ%20Êç∑&op=translate">Name
                                            Pronounce</a>
                                    </p>
                                </td>
                                <td style="padding:2.5%;width:40%;max-width:40%">
                                    <a href="images/id_square.jpeg"><img style="width:100%;max-width:100%"
                                            alt="profile photo" src="images/id_circle.png" class="hoverZoomLink"></a>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <h2>News</h2>
                                    <ul>
                                        <li>[2025/10] Honored to receive the <a href="https://www.sigmm.org/Awards/thesisaward">SIGMM Award for Outstanding PhD Thesis in Multimedia Computing, Communications, and Applications</a>! Many thanks to my advisor and all collaborators during my PhD study.</li>
                                        <li>[2025/09] Our paper <a href="https://arxiv.org/pdf/2410.21273">On Inductive Biases That Enable Generalization of Diffusion Transformers</a> is accepted by NeurIPS 2025.</li>
                                        <li>[2025/06] Our paper <a href="https://arxiv.org/pdf/2412.06029">Latent-Reframe: Enabling Camera Control for Video Diffusion Model without Training</a> is accepted by ICCV 2025.</li>
                                        <li>[2025/05] Excited to be selected for the <a href="https://cvpr.thecvf.com/Conferences/2025/CallForDoctoralConsortium">CVPR 2025 Doctoral Consortium</a>!</li>
                                        <li>[2025/04] Our paper <a href="https://arxiv.org/pdf/2312.17432">Video Understanding with Large Language Models: A Survey</a> is accepted by TCSVT.</li>
                                        <li>[2024/12] Our paper <a href="https://arxiv.org/abs/2501.09019">Ouroboros-Diffusion: Exploring Consistent Content Generation in Tuning-free Long Video Diffusion</a> is accepted to AAAI 2025.</li>
                                        <li>[2024/06] Our paper <a href="https://arxiv.org/abs/2305.04923">Learning to Evaluate the Artness of AI-generated Images</a> is accepted by TMM.</li>
                                        <li>[2024/06] Our paper <a href="https://arxiv.org/pdf/2310.07749">OpenLEAF: Open-Domain Interleaved Image-Text Generation and Evaluation</a> is accepted to ACM MM 2024 BNI track.</li>
                                        <li>[2024/05] Our paper <a href="https://arxiv.org/pdf/2401.02414">Bring Metric Functions into Diffusion Models</a> is accepted to IJCAI 2024.</li>
                                        <li>[2024/03] We will organize the first workshop on <a href="https://t2mmg.github.io/t2mm2024/">Visual-Language Alignment in Text-Guided Multi-Modal Generation (T2MM)</a> in conjunction with #<a href="https://2024.ieeeicme.org"></a>ICME2024. <a href="https://cmt3.research.microsoft.com/ICME2024W">Welcome to submit your workshop papers!</a></li>
                                        <li>[2024/03] I will join Apple as a research intern this summer.</li>
                                        <li>[2023/02] I will join <a
                                                href="https://www.microsoft.com/en-us/research/group/cognitive-services-research/">Microsoft
                                                Cloud & AI</a> as a research intern.</li>
                                    </ul>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <h2>Thesis</h2>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    <table width="100%" align="center" border="0">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <ul>
                                        <li><a href="https://www.proquest.com/dissertations-theses/text-video-generation-based-on-diffusion-model/docview/3206719586/se-2">
                                            <span class="papertitle">Text-to-Video Generation Based on Diffusion Model</span>
                                            </a> by Jie An, advised by Jiebo Luo, University of Rochester</li>
                                    </ul>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <h2>Publications &amp; Preprints</h2>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>

                            <tr onmouseout="inductivebias_stop()" onmouseover="inductivebias_start()">
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one">
                                        <div class="two" id='inductivebias_image'>
                                            <img src='images/inductivebias_before.png' width="160">
                                        </div>
                                        <img src='images/inductivebias_before.png' width="160">
                                    </div>
                                    <script type="text/javascript">
                                        function inductivebias_start() {
                                            document.getElementById('inductivebias_image').style.opacity = "1";
                                        }

                                        function inductivebias_stop() {
                                            document.getElementById('inductivebias_image').style.opacity = "0";
                                        }
                                        inductivebias_stop()
                                    </script>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://arxiv.org/abs/2410.21273">
                                        <span class="papertitle">On Inductive Biases That Enable Generalization of Diffusion Transformers</span>
                                    </a>
                                    <br>
                                        <strong>Jie An</strong>, De Wang, Pengsheng Guo, Jiebo Luo, Alexander Schwing
                                    <br>
                                    <em>NeurIPS 2025</em>
                                    &nbsp|&nbsp
                                    <a href="https://dit-generalization.github.io" target="_blank">Project Page</a>
                                    &nbsp|&nbsp
                                    <a href="https://github.com/DiT-Generalization/DiT-Generalization" target="_blank">Code</a>
                                    &nbsp|&nbsp
                                    <a href="https://machinelearning.apple.com/research/on-inductive-biases" target="_blank">Featured at Apple MLR</a>
                                    &nbsp|&nbsp
                                    <a href="bibs/inductivebias.txt" target="_blank">BibTex</a>
                                    <p></p>
                                    <p>
                                        <span style="color: gray;">We find that the generalization ability of DiTs is linked to an attention locality bias: despite access to global tokens, DiTs naturally develop locality patterns in certain attention layers.</span>
                                    </p>
                                </td>
                            </tr>

                            <tr onmouseout="latentreframe_stop()" onmouseover="latentreframe_start()">
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one">
                                        <div class="two" id='latentreframe_image'>
                                            <img src='images/latentreframe_after.png' width="160">
                                        </div>
                                        <img src='images/latentreframe_after.png' width="160">
                                    </div>
                                    <script type="text/javascript">
                                        function latentreframe_start() {
                                            document.getElementById('latentreframe_image').style.opacity = "1";
                                        }

                                        function latentreframe_stop() {
                                            document.getElementById('latentreframe_image').style.opacity = "0";
                                        }
                                        latentreframe_stop()
                                    </script>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://arxiv.org/abs/2412.06029">
                                        <span class="papertitle">Latent-Reframe: Enabling Camera Control for Video Diffusion Model without Training</span>
                                    </a>
                                    <br>
                                        Zhenghong Zhou<sup>*</sup>, <strong>Jie An</strong><sup>*</sup>, Jiebo Luo
                                    <br>
                                    <em>ICCV 2025</em>
                                    &nbsp|&nbsp
                                    <a href="https://latent-reframe.github.io" target="_blank">Project Page</a>
                                    &nbsp|&nbsp
                                    <a href="bibs/latentreframe.txt" target="_blank">BibTex</a>
                                    <p></p>
                                    <p>
                                        <span style="color: gray;">We incorporate a 3D point cloud model based on MonST3R into a video diffusion model, which enables arbitrary camera trajectory control in video generation, without training.</span>
                                    </p>
                                </td>
                            </tr>

                            <tr onmouseout="ouroboros_stop()" onmouseover="ouroboros_start()">
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one">
                                        <div class="two" id='ouroboros_image'>
                                            <img src='images/ouroboros_before.png' width="160">
                                        </div>
                                        <img src='images/ouroboros_before.png' width="160">
                                    </div>
                                    <script type="text/javascript">
                                        function ouroboros_start() {
                                            document.getElementById('ouroboros_image').style.opacity = "1";
                                        }

                                        function ouroboros_stop() {
                                            document.getElementById('ouroboros_image').style.opacity = "0";
                                        }
                                        ouroboros_stop()
                                    </script>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://arxiv.org/abs/2501.09019">
                                        <span class="papertitle">Ouroboros-Diffusion: Exploring Consistent Content Generation in Tuning-free Long Video Diffusion</span>
                                    </a>
                                    <br>
                                        Jingyuan Chen, Fuchen Long, <strong>Jie An</strong>, Zhaofan Qiu, Ting Yao, Jiebo Luo, Tao Mei
                                    <br>
                                    <em>AAAI 2025</em>
                                    &nbsp|&nbsp
                                    <a href="bibs/ouroboros.txt" target="_blank">BibTex</a>
                                    <p></p>
                                    <p>
                                        <span style="color: gray;">We introduce a FIFO-style training-free approach that can enable a video diffusion model to generate infinite long videos in sampling stage.</span>
                                    </p>
                                </td>
                            </tr>

                            <tr onmouseout="videollm_stop()" onmouseover="videollm_start()">
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one">
                                        <div class="two" id='videollm_image'>
                                            <img src='images/videollm_before.png' width="160">
                                        </div>
                                        <img src='images/videollm_before.png' width="160">
                                    </div>
                                    <script type="text/javascript">
                                        function videollm_start() {
                                            document.getElementById('videollm_image').style.opacity = "1";
                                        }

                                        function videollm_stop() {
                                            document.getElementById('videollm_image').style.opacity = "0";
                                        }
                                        videollm_stop()
                                    </script>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://arxiv.org/pdf/2312.17432">
                                        <span class="papertitle">Video Understanding with Large Language Models: A Survey</span>
                                    </a>
                                    <br>
                                        Y. Tang, J. Bi, S. Xu, L. Song, S. Liang, T. Wang, D. Zhang, <strong>Jie An</strong> and others
                                    <br>
                                    <em>TCSVT</em>
                                    &nbsp|&nbsp
                                    <a href="https://github.com/yunlong10/Awesome-LLMs-for-Video-Understanding" target="_blank">GitHub</a>
                                    &nbsp|&nbsp
                                    <a href="bibs/videollm.txt" target="_blank">BibTex</a>
                                    <p></p>
                                    <p>
                                        <span style="color: gray;">We present a comprehensive survey about using LLMs/LMMs for video understanding.</span>
                                    </p>
                                </td>
                            </tr>

                            <tr onmouseout="openleaf_stop()" onmouseover="openleaf_start()">
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one">
                                        <div class="two" id='openleaf_image'>
                                            <img src='images/openleaf_before.png' width="160">
                                        </div>
                                        <img src='images/openleaf_before.png' width="160">
                                    </div>
                                    <script type="text/javascript">
                                        function openleaf_start() {
                                            document.getElementById('openleaf_image').style.opacity = "1";
                                        }

                                        function openleaf_stop() {
                                            document.getElementById('openleaf_image').style.opacity = "0";
                                        }
                                        openleaf_stop()
                                    </script>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://arxiv.org/pdf/2310.07749">
                                        <span class="papertitle">OpenLEAF: Open-Domain Interleaved Image-Text Generation and Evaluation</span>
                                    </a>
                                    <br>
                                        <strong>Jie An</strong><sup>*</sup>, Zhengyuan Yang, Linjie Li, Jianfeng Wang, Kevin Lin, Zicheng Liu, Lijuan Wang, Jiebo Luo
                                    <br>
                                    <em>ACM MM (BNI Track)</em> 2024
                                    &nbsp|&nbsp
                                    <a href="bibs/openleaf.txt" target="_blank">BibTex</a>
                                    <p></p>
                                    <p>
                                        <span style="color: gray;">We introduce a benchmark dataset, an evaluation pipeline, and a set of baseline models for interleaved image-text generation task.</span>
                                    </p>
                                </td>
                            </tr>

                            <tr onmouseout="casdm_stop()" onmouseover="casdm_start()">
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one">
                                        <div class="two" id='casdm_image'>
                                            <img src='images/casdm.png' width="160">
                                        </div>
                                        <img src='images/casdm.png' width="160">
                                    </div>
                                    <script type="text/javascript">
                                        function casdm_start() {
                                            document.getElementById('casdm_image').style.opacity = "1";
                                        }

                                        function casdm_stop() {
                                            document.getElementById('casdm_image').style.opacity = "0";
                                        }
                                        casdm_stop()
                                    </script>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://arxiv.org/pdf/2401.02414">
                                        <span class="papertitle">Bring Metric Functions into Diffusion Models</span>
                                    </a>
                                    <br>
                                        <strong>Jie An</strong>, Zhengyuan Yang, Jianfeng Wang, Linjie Li, Zicheng Liu, Lijuan Wang, Jiebo Luo
                                    <br>
                                    <em>IJCAI</em> 2024
                                    &nbsp|&nbsp
                                    <a href="bibs/casdm.txt" target="_blank">BibTex</a>
                                    <p></p>
                                    <p>
                                        <span style="color: gray;">We study how to ultilize LPIPS loss in diffusion model training to improve the image generation quality.</span>
                                    </p>
                                </td>
                            </tr>

                            <tr onmouseout="latentshift_stop()" onmouseover="latentshift_start()">
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one">
                                        <div class="two" id='latentshift_image'>
                                            <img src='images/latentshift_after.png' width="160">
                                        </div>
                                        <img src='images/latentshift_before.png' width="160">
                                    </div>
                                    <script type="text/javascript">
                                        function latentshift_start() {
                                            document.getElementById('latentshift_image').style.opacity = "1";
                                        }

                                        function latentshift_stop() {
                                            document.getElementById('latentshift_image').style.opacity = "0";
                                        }
                                        latentshift_stop()
                                    </script>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://arxiv.org/abs/2304.08477">
                                        <span class="papertitle">Latent-Shift: Latent Diffusion with Temporal Shift for Efficient Text-to-Video Generation</span>
                                    </a>
                                    <br>
                                        <strong>Jie An</strong><sup>*</sup>, Songyang Zhang<sup>*</sup>, Harry Yang, Sonal Gupta, Jia-Bin Huang, Jiebo Luo and Xi Yin
                                    <br>
                                    <em>Arxiv</em> 2023
                                    &nbsp|&nbsp
                                    <a href="https://latent-shift.github.io/" target="_blank">Project Page</a>
                                    &nbsp|&nbsp
                                    <a href="bibs/latentshift.txt" target="_blank">BibTex</a>
                                    <p></p>
                                    <p>
                                        <span style="color: gray;">We propose an efficient text-to-video generation method based on latent diffusion model and temporal shift.</span>
                                    </p>
                                </td>
                            </tr>


                            <tr onmouseout="artscore_stop()" onmouseover="artscore_start()">
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one">
                                        <div class="two" id='artscore_image'>
                                            <img src='images/artscore.png' width="160">
                                        </div>
                                        <img src='images/artscore.png' width="160">
                                    </div>
                                    <script type="text/javascript">
                                        function artscore_start() {
                                            document.getElementById('artscore_image').style.opacity = "1";
                                        }

                                        function artscore_stop() {
                                            document.getElementById('artscore_image').style.opacity = "0";
                                        }
                                        artscore_stop()
                                    </script>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://arxiv.org/abs/2305.04923">
                                        <span class="papertitle">Learning to Evaluate the Artness of AI-generated Images</span>
                                    </a>
                                    <br>
                                        Junyu Chen, <strong>Jie An</strong>, Hanjia Lyu, Jiebo Luo
                                    <br>
                                    <em>TMM</em> 2024
                                    &nbsp|&nbsp
                                    <a href="bibs/artscore.txt" target="_blank">BibTex</a>
                                    <p></p>
                                    <p>
                                        <span style="color: gray;">We propose a rank-based method to evaluate the artness level of AI-generated artworks.</span>
                                    </p>
                                </td>
                            </tr>

                            <tr onmouseout="fef_stop()" onmouseover="fef_start()">
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one">
                                        <div class="two" id='fef_image'>
                                            <img src='images/fef.png' width="160">
                                        </div>
                                        <img src='images/fef.png' width="160">
                                    </div>
                                    <script type="text/javascript">
                                        function fef_start() {
                                            document.getElementById('fef_image').style.opacity = "1";
                                        }

                                        function fef_stop() {
                                            document.getElementById('fef_image').style.opacity = "0";
                                        }
                                        fef_stop()
                                    </script>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://arxiv.org/abs/2211.12981">
                                        <span class="papertitle">Holistic Visual-Textual Sentiment Analysis with Prior Models</span>
                                    </a>
                                    <br>
                                        Junyu Chen, <strong>Jie An</strong>, Hanjia Lyu and Jiebo Luo
                                    <br>
                                    <em>MIPR</em> 2024
                                    &nbsp|&nbsp
                                    <a href="bibs/fef.txt" target="_blank">BibTex</a>
                                    <p></p>
                                    <p>
                                            <span style="color: gray;">We ultilize multi-modal expert features to assist the sentiment analysis task.</span>
                                    </p>
                                </td>
                            </tr>

                            <tr onmouseout="quantart_stop()" onmouseover="quantart_start()">
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one">
                                        <div class="two" id='quantart_image'>
                                            <img src='images/quantart_after.png' width="160">
                                        </div>
                                        <img src='images/quantart_before.png' width="160">
                                    </div>
                                    <script type="text/javascript">
                                        function quantart_start() {
                                            document.getElementById('quantart_image').style.opacity = "1";
                                        }

                                        function quantart_stop() {
                                            document.getElementById('quantart_image').style.opacity = "0";
                                        }
                                        quantart_stop()
                                    </script>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://arxiv.org/abs/2212.10431">
                                        <span class="papertitle">QuantArt: Quantizing Image Style Transfer Towards High Visual Fidelity</span>
                                    </a>
                                    <br>
                                        Siyu Huang<sup>*</sup>, <strong>Jie An</strong><sup>*</sup>, Donglai Wei, Jiebo Luo and Hanspeter Pfister
                                    <br>
                                    <em>CVPR</em> 2023
                                    &nbsp|&nbsp
                                    <a href="https://github.com/siyuhuang/QuantArt" target="_blank">Code</a>
                                    &nbsp|&nbsp
                                    <a href="bibs/quantart.txt" target="_blank">BibTex</a>
                                    <p></p>
                                    <p>
                                        <span style="color: gray;">QuantArt allows the style transfer model take the reference from the whole artistic picture dataset, leading to improved visual fidelity.</span>
                                    </p>
                                </td>
                            </tr>

                            <tr onmouseout="mav_stop()" onmouseover="mav_start()">
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one">
                                        <div class="two" id='mav_image'>
                                            <img src='images/mav_after.png' width="160">
                                        </div>
                                        <img src='images/mav_before.png' width="160">
                                    </div>
                                    <script type="text/javascript">
                                        function mav_start() {
                                            document.getElementById('mav_image').style.opacity = "1";
                                        }

                                        function mav_stop() {
                                            document.getElementById('mav_image').style.opacity = "0";
                                        }
                                        mav_stop()
                                    </script>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://arxiv.org/pdf/2209.14792.pdf">
                                        <span class="papertitle">Make-A-Video: Text-to-video Generation Without Text-video Data.</span>
                                    </a>
                                    <br>
                                        Uriel Singer<sup>*</sup>, Adam Polyak<sup>*</sup>, Thomas Hayes<sup>*</sup>, Xi Yin<sup>*</sup>, <strong>Jie An</strong>, Songyang Zhang, Qiyuan Hu, Harry Yang, Oron Ashual, Oran Gafni, Devi Parikh, Sonal Gupta and Yaniv Taigman
                                    <br>
                                    <em>ICLR</em> 2023
                                    &nbsp|&nbsp
                                    <a href="bibs/mav.txt" target="_blank">BibTex</a>
                                    <p></p>
                                    <p>
                                            <span style="color: gray;">We propose a text-to-video generation method based on diffusion model.</span>
                                    </p>
                                </td>
                            </tr>


                            <tr onmouseout="anchor_stop()" onmouseover="anchor_start()">
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one">
                                        <div class="two" id='anchor_image'>
                                            <img src='images/anchor_after.png' width="160">
                                        </div>
                                        <img src='images/anchor_before.png' width="160">
                                    </div>
                                    <script type="text/javascript">
                                        function anchor_start() {
                                            document.getElementById('anchor_image').style.opacity = "1";
                                        }

                                        function anchor_stop() {
                                            document.getElementById('anchor_image').style.opacity = "0";
                                        }
                                        anchor_stop()
                                    </script>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://arxiv.org/pdf/2306.14879.pdf">
                                        <span class="papertitle">Domain-Scalable Unpaired Image Translation via Latent Space Anchoring</span>
                                    </a>
                                    <br>
                                        Siyu Huang<sup>*</sup>, <strong>Jie An</strong><sup>*</sup> , Donglai Wei, Zudi Lin, Jiebo Luo and Hanspeter Pfister
                                    <br>
                                    <em>TPAMI</em>
                                    &nbsp|&nbsp
                                    <a href="https://github.com/siyuhuang/Latent-Space-Anchoring" target="_blank">Code</a>
                                    &nbsp|&nbsp
                                    <a href="bibs/anchor.txt" target="_blank">BibTex</a>
                                    <p></p>
                                    <p>
                                        <span style="color: gray;">We propose a GAN-based multi-domain image translation method that can extend to any unseen domain without the need to train the core backbone.</span>
                                    </p>
                                </td>
                            </tr>


                            <tr onmouseout="bab_stop()" onmouseover="bab_start()">
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one">
                                        <div class="two" id='bab_image'>
                                            <img src='images/bab_after.png' width="160">
                                        </div>
                                        <img src='images/bab_before.png' width="160">
                                    </div>
                                    <script type="text/javascript">
                                        function bab_start() {
                                            document.getElementById('bab_image').style.opacity = "1";
                                        }

                                        function bab_stop() {
                                            document.getElementById('bab_image').style.opacity = "0";
                                        }
                                        bab_stop()
                                    </script>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://openaccess.thecvf.com/content/WACV2023/papers/An_Is_Bigger_Always_Better_An_Empirical_Study_on_Efficient_Architectures_WACV_2023_paper.pdf">
                                        <span class="papertitle">Is Bigger Always Better? An Empirical Study on Efficient Architectures for Style Transfer and Beyond</span>
                                    </a>
                                    <br>
                                        <strong>Jie An</strong>, Tao Li, Haozhi Huang, Jinwen Ma and Jiebo Luo
                                    <br>
                                    <em>WACV</em> 2023
                                    &nbsp|&nbsp
                                    <a href="bibs/bab.txt" target="_blank">BibTex</a>
                                    <p></p>
                                    <p>
                                        <span style="color: gray;">We study whether the big VGG19 architecture is the best backbone for image style transfer and explore its efficient alternatives.</span>
                                    </p>
                                </td>
                            </tr>

                            <tr onmouseout="fat_stop()" onmouseover="fat_start()">
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one">
                                        <div class="two" id='fat_image'>
                                            <img src='images/fat_after.png' width="160">
                                        </div>
                                        <img src='images/fat_before.png' width="160">
                                    </div>
                                    <script type="text/javascript">
                                        function fat_start() {
                                            document.getElementById('fat_image').style.opacity = "1";
                                        }

                                        function fat_stop() {
                                            document.getElementById('fat_image').style.opacity = "0";
                                        }
                                        fat_stop()
                                    </script>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://arxiv.org/abs/2104.02894">
                                        <span class="papertitle">Facial Attribute Transformers for Precise and Robust Makeup Transfer</span>
                                    </a>
                                    <br>
                                    Zhaoyi Wan, Haoran Chen, <strong>Jie An</strong>, Wentao Jiang, Cong Yao and Jiebo Luo
                                    <br>
                                    <em>WACV</em> 2022
                                    &nbsp|&nbsp
                                    <a href="bibs/fat.txt" target="_blank">BibTex</a>
                                    <p></p>
                                    <p>
                                        <span style="color: gray;">We propose an new transformer-based method for makeup transfer and removal.</span>
                                    </p>
                                </td>
                            </tr>

                            <tr onmouseout="artflow_stop()" onmouseover="artflow_start()">
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one">
                                        <div class="two" id='artflow_image'>
                                            <img src='images/artflow_after.png' width="160">
                                        </div>
                                        <img src='images/artflow_before.png' width="160">
                                    </div>
                                    <script type="text/javascript">
                                        function artflow_start() {
                                            document.getElementById('artflow_image').style.opacity = "1";
                                        }

                                        function artflow_stop() {
                                            document.getElementById('artflow_image').style.opacity = "0";
                                        }
                                        artflow_stop()
                                    </script>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://arxiv.org/abs/2103.16877">
                                        <span class="papertitle">ArtFlow: Unbiased Image Style Transfer via Reversible
                                            Neural Flows</span>
                                    </a>
                                    <br>
                                    <strong>Jie An</strong><sup>*</sup>, Siyu Huang<sup>*</sup>, Yibing Song, Dejing
                                    Dou, Wei Liu and Jiebo Luo
                                    <br>
                                    <em>CVPR</em> 2021
                                    &nbsp|&nbsp
                                    <a href="https://github.com/pkuanjie/ArtFlow" target="_blank">Code</a>
                                    &nbsp|&nbsp
                                    <a href="bibs/artflow.txt" target="_blank">BibTex</a>
                                    <p></p>
                                    <p>
                                        <span style="color: gray;">We propose an unbiased style transfer method based
                                            on neural flows to address the content leak issue in style transfer.</span>
                                    </p>
                                </td>
                            </tr>


                            <tr onmouseout="global_sentiment_stop()" onmouseover="global_sentiment_start()">
                                <td style="padding:20px;width:25%;vertical-align:middle;">
                                    <div class="one">
                                        <div class="two" id='global_sentiment_image'>
                                            <img src='images/gst_after.png' width="160">
                                        </div>
                                        <img src='images/gst_before.png' width="160">
                                    </div>
                                    <script type="text/javascript">
                                        function global_sentiment_start() {
                                            document.getElementById('global_sentiment_image').style.opacity = "1";
                                        }

                                        function global_sentiment_stop() {
                                            document.getElementById('global_sentiment_image').style.opacity = "0";
                                        }
                                        global_sentiment_stop()
                                    </script>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://arxiv.org/pdf/2006.11989">
                                        <span class="papertitle">Global Image Sentiment Transfer</span>
                                    </a>
                                    <br>
                                    <strong>Jie An</strong>, Tianlang Chen, Songyang Zhang and Jiebo Luo
                                    <br>
                                    <em>ICPR</em> 2020
                                    &nbsp|&nbsp
                                    <a href="bibs/gst.txt" target="_blank">BibTex</a>
                                    <p></p>
                                    <p>
                                        <span style="color: gray;">We propose a method to transfer the global sentiment
                                            of images.</span>
                                    </p>
                                </td>
                            </tr>


                            <tr onmouseout="stylenas_stop()" onmouseover="stylenas_start()">
                                <td style="padding:20px;width:25%;vertical-align:middle;">
                                    <div class="one">
                                        <div class="two" id='stylenas_image'>
                                            <img src='images/stylenas_after.png' width="160">
                                        </div>
                                        <img src='images/stylenas_before.png' width="160">
                                    </div>
                                    <script type="text/javascript">
                                        function stylenas_start() {
                                            document.getElementById('stylenas_image').style.opacity = "1";
                                        }

                                        function stylenas_stop() {
                                            document.getElementById('stylenas_image').style.opacity = "0";
                                        }
                                        stylenas_stop()
                                    </script>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://arxiv.org/pdf/1912.02398">
                                        <span class="papertitle">Ultrafast photorealistic style transfer via neural architecture search</span>
                                    </a>
                                    <br>
                                    <strong>Jie An</strong><sup>*</sup>, Haoyi Xiong<sup>*</sup>, kun Huan and Jiebo Luo
                                    <br>
                                    <em>AAAI</em> 2020 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
                                    &nbsp|&nbsp
                                    <a href="https://github.com/Richard-An/StyleNAS" target="_blank">Code</a></u>
                                    &nbsp|&nbsp
                                    <a href="bibs/stylenas.txt" target="_blank">BibTex</a>
                                    <p></p>
                                    <p>
                                        <span style="color: gray;">We propose a neural architecture search framework to discover efficient architectures for photo-realistic style transfer.</span>
                                    </p>
                                </td>
                            </tr>


                            <tr onmouseout="pan_stop()" onmouseover="pan_start()">
                                <td style="padding:20px;width:25%;vertical-align:middle;">
                                    <div class="one">
                                        <div class="two" id='pan_image'>
                                            <img src='images/pan.png' width="160">
                                        </div>
                                        <img src='images/pan.png' width="160">
                                    </div>
                                    <script type="text/javascript">
                                        function pan_start() {
                                            document.getElementById('pan_image').style.opacity = "1";
                                        }

                                        function pan_stop() {
                                            document.getElementById('pan_image').style.opacity = "0";
                                        }
                                        pan_stop()
                                    </script>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://arxiv.org/pdf/1805.10180">
                                        <span class="papertitle">Pyramid attention network for semantic segmentation</span>
                                    </a>
                                    <br>
                                    Hanchao Li, Pengfei Xiong, <strong>Jie An</strong>, and Lingxue Wang
                                    <br>
                                    <em>BMVC</em> 2018
                                    &nbsp|&nbsp
                                    <a href="bibs/pan.txt" target="_blank">BibTex</a>
                                    <p></p>
                                    <p>
                                        <span style="color: gray;">We propose a new network architecture for semantic image segmentation.</span>
                                    </p>
                                </td>
                            </tr>

                        </tbody>
                    </table>

                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <h2>Invited Talks</h2>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    <table width="100%" align="center" border="0">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <ul>
                                        <li>[2026/01] "On Diffusion-Based Visual Content Generation: From Base Model to Methodology and Evaluation" @ Apple, MLR</li>
                                        <li>[2025/03] "On Diffusion-Based Visual Content Generation: From Base Model to Methodology and Evaluation" @ Meta, Reality Labs</li>
                                        <li>[2025/02] "On Diffusion-Based Visual Content Generation: From Base Model to Methodology and Evaluation" @ Clemson University, Computer Science</li>
                                    </ul>
                                </td>
                            </tr>
                        </tbody>
                    </table>

                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <h2>Work &amp; Internships</h2>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:25%;vertical-align:middle;">
                                    <div class="one">
                                        <img src='images/amazon.png' width="160">
                                    </div>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://amazon.jobs/content/en/teams/agi">Amazon AGI</a>
                                    <br>
                                        [2025/07 - Current] Applied Scientist
                                    <br>
                                        Video Generation Architecture, Parallelism, and Pre-training.</br>
                                        Omni Understanding and Generation Models.</br>
                                        Reinforcement Learning for Image Generation.
                                </td>
                            </tr>
                            <tr>
                                <td style="padding:20px;width:25%;vertical-align:middle;">
                                    <div class="one">
                                        <img src='images/meta.png' width="160">
                                    </div>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://tech.facebook.com/reality-labs/">Meta Reality Lab</a>
                                    <br>
                                        [2025/05 - 2025/07] AI Research Scientist
                                    <br>
                                        3D Generation and World Modeling.
                                </td>
                            </tr>
                            <tr>
                                <td style="padding:20px;width:25%;vertical-align:middle;">
                                    <div class="one">
                                        <img src='images/apple.png' width="70">
                                    </div>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://machinelearning.apple.com">Apple</a>
                                    <br>
                                        [2024/05 - 2025/04] Research Intern
                                    <br>
                                        Advisors: <a href="https://www.alexander-schwing.de">Alexander Schwing</a>, <a href="https://scholar.google.com/citations?user=QiWbLt8AAAAJ&hl=en">Andy (De) Wang</a>, <a href="https://psguo.github.io">Pengsheng Guo</a>
                                    <br>
                                        Project: Diffusion Model Analysis
                                </td>
                            </tr>
                            <tr>
                                <td style="padding:20px;width:25%;vertical-align:middle;">
                                    <div class="one">
                                        <img src='images/microsoft.png' width="160">
                                    </div>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://www.microsoft.com/en-us/research/group/cognitive-services-research/">Microsoft Cloud & AI</a>
                                    <br>
                                        [2023/02 - 2024/4] Research Intern
                                    <br>
                                        Advisors: <a href="https://zyang-ur.github.io/">Zhengyuan Yang</a>, Jianfeng Wang, Linjie Li, Lijuan Wang, Zicheng Liu
                                    <br>
                                        Project: Diffusion Model and Visual-Language Generation.
                                </td>
                            </tr>
                            <tr>
                                <td style="padding:20px;width:25%;vertical-align:middle;">
                                    <div class="one">
                                        <img src='images/meta.png' width="160">
                                    </div>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://ai.meta.com/research/">Meta FAIR</a>
                                    <br>
                                        [2022/05 - 2022/12] Research Intern
                                    <br>
                                        Advisors: <a href="https://scholar.google.com/citations?user=jpIFgToAAAAJ">Harry Yang</a>, <a href="https://xiyinmsu.github.io/">Xi Yin</a>, Sonal Gupta 
                                    <br>
                                        Project: Text-to-Video Generation.
                                </td>
                            </tr>
                        </tbody>
                    </table>

                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <h2>Collaborators</h2>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    <table width="100%" align="center" border="0">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <ul>
                                        <li>[2025] Zhenghong Zhou, Ph.D., University of Rochester.
                                        <li>[2025] Jingyuan (Patrick) Chen, B.S., University of Rochester, now M.S. at University of Pennsylvania.
                                        <li>[2024] Yunlong Tang, Ph.D., University of Rochester.
                                        <li>[2023-2024] Junyu Chen, M.S., University of Rochester, now Ph.D. at University of Rochester.
                                        <li>[2023] Alexander Martin, B.S., University of Rochester, now Ph.D. at Johns Hopkins University.
                                        <li>[2023] Songyang Zhang, Ph.D., University of Rochester, now researcher at Utopic Studio.
                                        <li>[2023] Tao Li, Ph.D., Peking University.
                                        <li>[2022] Zhaoyi Wan, researcher, Megvii, now researcher at JQ Investments.
                                        <li>[2021-2023] Siyu Huang, researcher, Baidu, now professor at Clemson University.
                                        <li>[2018] Hanchao Li, intern, Megvii, now engineer at Microsoft (Redmond).
                                    </ul>
                                </td>
                            </tr>
                        </tbody>
                    </table>

                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <h2>Academic Services</h2>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    <table width="100%" align="center" border="0">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <h3>Conference Reviewer</h3>
                                    <ul>
                                        <li>CVPR, ICCV, ECCV, NeurIPS, ICLR, ICML, WACV, EMNLP, ACL, MM, AAAI, ICASSP, ICME</li>
                                    </ul>
                                    <h3>Journal Reviewer</h3>
                                    <ul>
                                        <li>TPAMI, TMM, TNNLS, APSIPA</li>
                                    </ul>
                                </td>
                            </tr>
                        </tbody>
                    </table>

                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <h2>Honors &amp; Awards</h2>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    <table width="100%" align="center" border="0">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <ul>
                                        <li>[2025/10] SIGMM Award for Outstanding PhD Thesis</li>
                                        <li>[2025/06] Selection for Doctoral Consortium, CVPR 2025</li>
                                        <li>[2019/06] Outstanding Graduate of Beijing</li>
                                        <li>[2018/10] Graduate student scholarship, Peking University</li>
                                        <li>[2016/10] Graduate student scholarship, Peking University</li>
                                        <li>[2015/06] ‚ÄúGuang Hua‚Äù scholarship, Peking University</li>
                                    </ul>
                                </td>
                            </tr>
                        </tbody>
                    </table>

                    <!-- <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=200&t=m&d=igbJhVb6cuB_82zXfJPDgGalhD6q8UFjGDGHVcMQp5o&co=2d78ad&cmo=3acc3a&cmn=ff5353&ct=ffffff"></script> -->
                    <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=200&t=m&d=XNq2M4F_hUg7iS7xFFT-ptJqbcyITEWLXNTCTCiHCAA'></script>

                    <div align="right">
                    <a href="https://github.com/jonbarron/jonbarron_website">Template</ahref>
                    </div>
                </td>
            </tr>
    </table>
</body>

</html>
